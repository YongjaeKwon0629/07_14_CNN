## 6. ì˜ˆì œ ì½”ë“œ (PyTorch)

ì´ ì„¹ì…˜ì—ì„œëŠ” PyTorchë¥¼ ì‚¬ìš©í•œ **ê°„ë‹¨í•œ CNN ëª¨ë¸ êµ¬í˜„ ì˜ˆì œ**ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤.  
MNIST(ì†ê¸€ì”¨ ìˆ«ì ì´ë¯¸ì§€)ì²˜ëŸ¼ í¬ê¸°ê°€ ì‘ì€ 28x28 ì´ë¯¸ì§€ì— ì í•©í•œ êµ¬ì¡°ë¡œ ì„¤ê³„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

### ğŸ§± ëª¨ë¸ êµ¬ì¡°

- ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°: 28x28, ì±„ë„ 1ê°œ (í‘ë°±)
- Convolution â†’ ReLU â†’ Max Pooling
- Convolution â†’ ReLU â†’ Max Pooling
- Flatten â†’ Fully Connected â†’ ì¶œë ¥ (10 í´ë˜ìŠ¤)

---

### ğŸ§ª ì½”ë“œ êµ¬í˜„

```
import torch
import torch.nn as nn
import torch.nn.functional as F

# CNN í´ë˜ìŠ¤ ì •ì˜
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        
        # ì²« ë²ˆì§¸ í•©ì„±ê³± ì¸µ: ì…ë ¥ ì±„ë„ 1ê°œ, ì¶œë ¥ ì±„ë„ 32ê°œ, í•„í„° í¬ê¸° 3x3
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
        
        # ë‘ ë²ˆì§¸ í•©ì„±ê³± ì¸µ: ì…ë ¥ 32ê°œ, ì¶œë ¥ 64ê°œ
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        
        # í’€ë§ ì¸µ (Max Pooling)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # ì™„ì „ ì—°ê²°ì¸µ (Flatten í›„ ì—°ê²°): 7x7x64 â†’ 10 í´ë˜ìŠ¤
        self.fc1 = nn.Linear(in_features=64 * 7 * 7, out_features=128)
        self.fc2 = nn.Linear(in_features=128, out_features=10)  # ìˆ«ì 0~9 ë¶„ë¥˜

    def forward(self, x):
        # ì²« ë²ˆì§¸ Conv â†’ ReLU â†’ Pooling
        x = self.pool(F.relu(self.conv1(x)))  # ì¶œë ¥: (32, 14, 14)

        # ë‘ ë²ˆì§¸ Conv â†’ ReLU â†’ Pooling
        x = self.pool(F.relu(self.conv2(x)))  # ì¶œë ¥: (64, 7, 7)

        # Flatten (ë²¡í„°ë¡œ í´ê¸°)
        x = x.view(-1, 64 * 7 * 7)

        # Fully Connected â†’ ReLU â†’ Fully Connected â†’ Softmax
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```          
